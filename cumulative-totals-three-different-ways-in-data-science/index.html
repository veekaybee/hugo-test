<!doctype html><html lang=en-us>
<head>
<meta http-equiv=x-clacks-overhead content="GNU Terry Pratchett">
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<link rel="shortcut icon" href=https://veekaybee.github.io/hugo-test/images/favicon.png>
<title>Cumulative totals three different ways in data science | ★★Vicki Boykis★★</title>
<meta name=title content="Cumulative totals three different ways in data science">
<meta name=description content="The data analysis field has moved away from querying tools like Crystal Reports (shudder), OLAP cubes, and Excel, to programming languages closer to the raw data.
I primarily work with IPython notebooks, R, and SQL these days, and I thought it would be interesting to look at the differences between these three tools and three ways of thinking through a single task.
Something people often ask of data scientists (or analysts or engineers or what have you) is to just find out how many total customers the company has from the very beginning on a cumulative basis.">
<meta name=keywords content>
<meta property="og:title" content="Cumulative totals three different ways in data science">
<meta property="og:description" content="The data analysis field has moved away from querying tools like Crystal Reports (shudder), OLAP cubes, and Excel, to programming languages closer to the raw data.
I primarily work with IPython notebooks, R, and SQL these days, and I thought it would be interesting to look at the differences between these three tools and three ways of thinking through a single task.
Something people often ask of data scientists (or analysts or engineers or what have you) is to just find out how many total customers the company has from the very beginning on a cumulative basis.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://veekaybee.github.io/hugo-test/cumulative-totals-three-different-ways-in-data-science/"><meta property="og:image" content="https://veekaybee.github.io/hugo-test/images/share.png"><meta property="article:section" content="blog">
<meta property="article:published_time" content="2015-07-08T00:00:00+00:00">
<meta property="article:modified_time" content="2015-07-08T00:00:00+00:00"><meta property="og:site_name" content="Hugo ʕ•ᴥ•ʔ Bear">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://veekaybee.github.io/hugo-test/images/share.png">
<meta name=twitter:title content="Cumulative totals three different ways in data science">
<meta name=twitter:description content="The data analysis field has moved away from querying tools like Crystal Reports (shudder), OLAP cubes, and Excel, to programming languages closer to the raw data.
I primarily work with IPython notebooks, R, and SQL these days, and I thought it would be interesting to look at the differences between these three tools and three ways of thinking through a single task.
Something people often ask of data scientists (or analysts or engineers or what have you) is to just find out how many total customers the company has from the very beginning on a cumulative basis.">
<meta itemprop=name content="Cumulative totals three different ways in data science">
<meta itemprop=description content="The data analysis field has moved away from querying tools like Crystal Reports (shudder), OLAP cubes, and Excel, to programming languages closer to the raw data.
I primarily work with IPython notebooks, R, and SQL these days, and I thought it would be interesting to look at the differences between these three tools and three ways of thinking through a single task.
Something people often ask of data scientists (or analysts or engineers or what have you) is to just find out how many total customers the company has from the very beginning on a cumulative basis."><meta itemprop=datePublished content="2015-07-08T00:00:00+00:00">
<meta itemprop=dateModified content="2015-07-08T00:00:00+00:00">
<meta itemprop=wordCount content="1579"><meta itemprop=image content="https://veekaybee.github.io/hugo-test/images/share.png">
<meta itemprop=keywords content>
<meta name=referrer content="no-referrer-when-downgrade">
<style>body{font-family:Verdana,sans-serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}</style>
</head>
<body>
<header><a href=/hugo-test/ class=title>
<h2>★★Vicki Boykis★★</h2>
</a>
<nav><a href=/hugo-test/>Home</a>
<a href=/hugo-test/blog>Blog</a>
</nav>
</header>
<main>
<h1>Cumulative totals three different ways in data science</h1>
<p>
<i>
<time datetime=2015-07-08 pubdate>
08 Jul, 2015
</time>
</i>
</p>
<content>
<p>The data analysis field has moved away from querying tools like Crystal Reports (<strong>shudder</strong>), OLAP cubes, and Excel, to programming languages closer to the raw data.</p>
<p>I primarily work with IPython notebooks, R, and SQL these days, and I thought it would be interesting to look at the differences between these three tools and three ways of thinking through a single task.</p>
<p>Something people often ask of data scientists (or analysts or engineers or what have you) is to just find out how many total customers the company has from the very beginning on a cumulative basis. Often product heads like to see this to figure out if their sexy new product is showing that legendary <a href=http://lunarmobiscuit.com/the-hockey-stick/>hockey stick growth</a>.</p>
<p>Often times, this data is only available at a granular level (i.e. you have a base number and the adds every month.) For example, let&rsquo;s say we want to find out how many total employees each of these Silicon Valley Companies have in any given month. Are they growing as quickly as Hooli?</p>
<p>Here&rsquo;s the CSV file you&rsquo;re given to work with: (also available in <a href=https://github.com/veekaybee/cumtotal>the associated GitHub repo</a> for all the code in this post.)</p>
<pre><code>Company	Month	New Employees	Hooli	    14-Jan	 123,456	Hooli	    14-Feb	   1,434	Hooli	    14-Mar	   2,455	Pied Piper	14-Jan	       1	Pied Piper	14-Feb	       2	Pied Piper	14-Mar	       2	Raviga	    14-Jan	      50	Raviga	    14-Feb	      -2	Raviga	    14-Mar	      17
</code></pre>
<p>But what we really want is this:</p>
<pre><code>Company	Month	New Employees	Hooli	    14-Jan	 123,456	Hooli	    14-Feb	 124,890	Hooli	    14-Mar	 127,345	Pied Piper	14-Jan	       1	Pied Piper	14-Feb	       3	Pied Piper	14-Mar	       5	Raviga	    14-Jan	      50	Raviga	    14-Feb	      48	Raviga	    14-Mar	      65
</code></pre>
<p>What I often want to do is create a cumulative total, by month and by company. In Excel, this is super-easy. Just add a new column and add the previous row&rsquo;s values to it. I&rsquo;ve shown the formula view:</p>
<p><img src=https://raw.githubusercontent.com/veekaybee/veekaybee.github.io/master/images/exceltot.png alt=Total></p>
<p>But, it&rsquo;s extremely annoying when there&rsquo;s any more than 100 rows of data, because then I&rsquo;m resorting to cut and paste and manually tweaking. As soon as I start to do things manually, I make mistakes, and it&rsquo;s <a href=https://github.com/jtleek/datasharing>not very good data practice</a> to have code you can&rsquo;t reproduce.</p>
<p>Doing this kind of thing in more data science-y environments is great because then you have reproducible code you can run over and over again. However, it does take a bit more legwork and requires thinking about the problem in a little bit of a different way than just summing cells.</p>
<p>So here are three typical ways to do cumulative totals in three pretty typical data science environments.</p>
<p>###Cumulative totals in Python</p>
<p>Python, like most programming languages, performs operations over rows of data sequentially, stopping when it hits a new column. (for example, it doesn&rsquo;t see data as a matrix, but more as individual values. )</p>
<p>This is a &ldquo;problem&rdquo; for data people with all languages: Software developers often see data as means to an end (compiling the program). This means data doesn&rsquo;t need to be organized exactly, just well enough to move through different pipes. Whereas for data people, data is the end goal. (If you&rsquo;re interested in more about this, I gave a presentation a year or so ago with graphics illustrating the topic <a href=http://www.slideshare.net/vickiboykis/analyst-30599322>here</a>.)</p>
<p>This &ldquo;problem&rdquo; (which is really just a feature of programming) is easy to solve with Pandas, which transforms data once again into matrices that need to be operated on in their entirerty. These matrices are called data frames. But it&rsquo;s a little unwieldy when performing operations on operations on matrices, so <a href=http://stackoverflow.com/questions/22650833/pandas-groupby-cumulative-sum>you have to do</a> a cumulative sum of a cumulative sum:</p>
<p>###Import Pandas for working with data</p>
<pre><code>import pandas as pd
from pandas import DataFrame
import dateutil.parser as parser
</code></pre>
<p>###Read in CSV file</p>
<pre><code>df=pd.read_csv('sv.csv')
print df
      Company   Month  New Employess
0       Hooli  14-Jan         123456
1       Hooli  14-Feb           1434
2       Hooli  14-Mar           2455
3  Pied Piper  14-Jan              1
4  Pied Piper  14-Feb              2
5  Pied Piper  14-Mar              2
6      Raviga  14-Jan             50
7      Raviga  14-Feb             -2
8      Raviga  14-Mar             17
</code></pre>
<p>###Make sure date and number values are rendered correctly from CSV file (the dateutil library) and check each column&rsquo;s datatype</p>
<pre><code>print df.dtypes
Company                  object
Month            datetime64[ns]
New Employess           float64
dtype: object
</code></pre>
<p>###Finally, roll up the cumulative total with two group-bys:</p>
<pre><code>print df.groupby(by=['Company','Month']).sum().groupby(level=[0]).cumsum()

                       New Employess
Company    Month                    
Hooli      2015-01-14         123456
           2015-02-14         124890
           2015-03-14         127345
Pied Piper 2015-01-14              1
           2015-02-14              3
           2015-03-14              5
Raviga     2015-01-14             50
           2015-02-14             48
           2015-03-14             65 
</code></pre>
<p>##Cumulative Totals in R</p>
<p>R, in theory, operates on matrices. But mostly, R &ldquo;thinks about data sets&rdquo; in columns as opposed to across both rows and columns. In order for it to understand matrices the same way databases do, you need to get the data.table package. (Check out <a href=http://stackoverflow.com/questions/22824662/calculate-cumulative-sum-of-one-column-based-on-another-columns-rank>this link</a> for more details.) It&rsquo;s a little more straightforward than Python because it handles CSV formatting a little better and you don&rsquo;t need to do as much pre-processing. Like Python, the data.table package has cumulative sum as a built-in function, but there are two steps to organizing the data correctly to be sorted instead of one.</p>
<p>Install the package, read in the csv file, set it as the data table, and set the two keys as the columns you want to group by, then run the cumulative sum function.</p>
<pre><code>install.packages(&quot;data.table&quot;)      
 sv &lt;- read.csv(&quot;~/Desktop/ipythondata/sv.csv&quot;) #read in data
require(data.table) #package for transforming to data table
View(sv)
setDT (sv) #set the table as your dataset
setkey(sv, Company,Month) 
sv[,csum := cumsum(New.Employees),by=c('Company')] 
View(sv) #view your results
</code></pre>
<p>And you get:</p>
<p><img src=https://raw.githubusercontent.com/veekaybee/veekaybee.github.io/master/images/rtotal.png alt=RTotal></p>
<p>##Cumulative Totals in SQL</p>
<p>This one is a little trickier because instead of running RStudio or IPython notebooks locally, you have to start a database instance&mldr;somewhere. You can, in theory, set up SQLite or MySQL locally, but it&rsquo;s probably more of a pain than it&rsquo;s worth.
I have a Digital Ocean droplet that has Postgres installed exactly for this kind of tomfoolery. <a href=https://wiki.postgresql.org/wiki/First_steps>There is a bunch of admin work</a> that will have to be done before you can create tables in Postgres, but then you&rsquo;re on your way on the command line:</p>
<pre><code> postgres@data:~$ psql
  postgres=# CREATE SCHEMA employees; 
  CREATE SCHEMA
  postgres=#  CREATE TABLE cumtot(company CHAR(50) NOT NULL, 
                                  month DATE NOT NULL,nemp NUMERIC NOT NULL);
  CREATE TABLE
</code></pre>
<p>Then take a look at the table that you&rsquo;ve created:
postgres=# \d
List of relations
Schema | Name | Type | Owner<br>
&mdash;&mdash;&ndash;+&mdash;&mdash;&ndash;+&mdash;&mdash;-+&mdash;&mdash;&mdash;-
public | cumtot | table | postgres</p>
<p>Then, let&rsquo;s copy the csv file into the table, instead of creating each row one by one:</p>
<pre><code>postgres=# copy cumtot FROM '/data/sv.csv' DELIMITER ',' CSV HEADER;
</code></pre>
<p>In the file, we first have to change the date format because Postgres only takes certain formats <a href=http://www.postgresql.org/docs/9.1/static/datatype-datetime.html>http://www.postgresql.org/docs/9.1/static/datatype-datetime.html</a></p>
<p>So what we&rsquo;re importing is:</p>
<pre><code>Company,Month,NewEmployees
Hooli,2014-Jan-01,123456
Hooli,2014-Feb-01,1434
Hooli,2014-Mar-01,2455
Pied Piper,2014-Jan-01,1
Pied Piper,2014-Feb-01,2
Pied Piper,2014-Mar-01,2
Raviga,2014-Jan-01,50
Raviga,2014-Feb-01,-2
Raviga,2014-Mar-01,17
</code></pre>
<p>Check out the table created with the \d command:</p>
<pre><code>    postgres=# \d cumtot
    Table &quot;public.cumtot&quot;
    Column  |     Type      | Modifiers 
    ---------+---------------+-----------
    company | character(50) | not null
    month   | date          | not null
    nemp    | numeric       | not null
</code></pre>
<p>And now view the contents of the table: (don&rsquo;t forget the semi-colon&mldr;Postgres is pretty picky with syntax):</p>
<pre><code>postgres=# select * from cumtot; 
company         |   month    |  nemp  
--------------------------------------
Hooli          | 2014-01-01 | 123456
Hooli          | 2014-02-01 |   1434
Hooli          | 2014-03-01 |   2455
Pied Piper     | 2014-01-01 |      1
Pied Piper     | 2014-02-01 |      2
Pied Piper     | 2014-03-01 |      2
Raviga         | 2014-01-01 |     50
Raviga         | 2014-02-01 |     48
Raviga         | 2014-03-01 |     65
</code></pre>
<p>That was just the pre-work gruntwork. Now we get to actually do the cumulative total, which requires a window function. <a href=http://sqlschool.modeanalytics.com/advanced/window-functions.html>Window functions</a> in SQL seem complicated but they&rsquo;re pretty easy once you get the hang of them. They say, &ldquo;don&rsquo;t look at this entire table, look at a portion of the table in a specific order.&rdquo;</p>
<pre><code>postgres=# SELECT company, month, nemp, sum(nemp) 
OVER (PARTITION BY company ORDER BY month) as cum_tot 
FROM cumtot ORDER BY company, month;

company                 |   month    |  nemp  | cum_tot 
Hooli                    | 2014-01-01 | 123456 |  123456
Hooli                    | 2014-02-01 |   1434 |  124890
Hooli                    | 2014-03-01 |   2455 |  127345
Pied Piper               | 2014-01-01 |      1 |       1
Pied Piper               | 2014-02-01 |      2 |       3
Pied Piper               | 2014-03-01 |      2 |       5
Raviga                   | 2014-01-01 |     50 |      50
Raviga                   | 2014-02-01 |     -2 |      48
Raviga                   | 2014-03-01 |     17 |      65 
</code></pre>
<p>And then you&rsquo;re done.</p>
<p>So that&rsquo;s pretty much it. Three different approaches to cumulative totals, that will each give you the right answer.</p>
<p>I worked with a tiny dataset that is lightning-fast in memory and very easy to transfer from place to place. The larger your dataset grows, the less you will want to move it. In this case, if you already have the data set up in a SQL database, keep it there and run your window function. It will take MUCH less time than exporting it out as a csv and importing it into either IPython or R. At the size of the data included in this post, it pretty much doesn&rsquo;t matter which one you use (although creating and importing into a database will take longer.)</p>
<p>###When to use what:</p>
<ul>
<li>Use IPython if you need to do further cleaning to the data after you cumulatively total it, and want to retrace your steps back to the original data.</li>
<li>Use R if you need to do simple statistics or regression or charting on the data as-is, and if the data is small.</li>
<li>Use SQL if your data&rsquo;s already in SQL and you need to create more groups from it.</li>
</ul>
</content>
<p>
</p>
</main>
<footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a>
</footer>
</body>
</html>